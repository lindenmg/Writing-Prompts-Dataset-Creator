{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2024 Gabriel Lindenmaier\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# In case of Jupyter notebooks leave out the __file__ variable.\n",
    "# AND ensure that the combination of \"..\" leads to the root directory\n",
    "project_root_path = os.path.realpath(os.path.join(\"../\"))\n",
    "sys.path.append(project_root_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "from src.utils.settings import Config\n",
    "from src.preprocessing.text_encoding import SentenceEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants & Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Take over DB table name from last notebook 04_dataset_tokenization for `s_encoding_meta` value:\n",
    "s_encoding_meta = \"unigram_700w_1024t_24k\"\n",
    "encoder = SentenceEncoder(batch_size=256\n",
    "                          , story_token_limit=1024\n",
    "                          , story_max_num_sentences=101\n",
    "                          , story_max_sentence_length=96\n",
    "                          , path_kv_store=Config.path.key_val_store\n",
    "                          , text_src_meta=s_encoding_meta\n",
    "                          , l_features=['mean_embeddings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "**Be aware from what database you are loading the tokenized text! That might change what you get - length-wise or token-style. See also *project_root*/notebooks/04_dataset_tokenization.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Database name: 'tokenized_small' currently for 512 token-limit; 'tokenized' for 768 limit;\n",
    "#                'tokenized_large' for 1024 token-limit\n",
    "data_base = Config.path.data_base\n",
    "sql_query = f\"\"\"\n",
    "SELECT t.prompt_bert_tokens, t.story_bert_tokens, t.prompt_idx, t.story_idx, t.story_sent_num\n",
    "FROM {s_encoding_meta} as t\n",
    "order by t.val ASC, t.prompt_idx ASC, t.story_score DESC;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(data_base)\n",
    "df = pd.read_sql_query(sql_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 243.9k for 1024 token limit; \n",
    "# 186k for 768 token limit; \n",
    "# 115.5k in case of 512 limit with BPE encoding \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sns.set(font_scale=1.2)\n",
    "_, ax = plt.subplots(figsize=[5, 4])\n",
    "sns.heatmap(df.corr(method='spearman'), ax=ax\n",
    "            , annot=True, annot_kws={'fontsize': 10}, fmt='.2f'\n",
    "            , cbar_kws={'label': 'Correlation Coefficient'}, cmap='viridis')\n",
    "ax.set_title(\"Stats Correlation Matrix\", fontsize=18)\n",
    "plt.show()\n",
    "plt.close()\n",
    "sns.set(font_scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 10min 2s in case of 512 story token limit & 65.5k text rows on highend desktop GPU with 64 batch\n",
    "# Wall time: 17min 25s in case of 768 story token limit & 95.6k text rows on highend desktop GPU with 128 batch\n",
    "# Wall time: 16min 22s in case of 1024 story token limit & 114.9k text rows on highend desktop GPU with 196 batch\n",
    "# Wall time: 56.8 s in case of 1024 tokens & 114.9k text rows for only embedding features\n",
    "# Wall time: 3min 20s as one above but one set of features has already been computed\n",
    "# Wall time: 1min 18s with 10 cores 3960x\n",
    "encoder.encode_prompts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 4h 4min 53s in case of 512 story token limit & 2.3M text rows on highend desktop GPU\n",
    "# Wall time: 8h 48min 53s in case of 768 story token limit & 5.1M text rows on highend desktop GPU\n",
    "# Wall time: 13h 59min 23s in case of 1024 story token limit & 8.18M text rows on highend desktop GPU\n",
    "# Wall time: 17min 1s in case of 1024 tokens & 8.18M text rows for only embedding features\n",
    "# Wall time: 43min 9s with 10 cores 3960x\n",
    "encoder.encode_stories(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
